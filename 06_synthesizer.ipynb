{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9641b1-af1f-4500-b35c-a2d6cf777174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🙌 Congratulations! You're now using a local Ollama model for all evals that \n",
      "require an LLM.\n",
      "🙌 Congratulations! You're now using local embeddings for all evals that require\n",
      "text embeddings.\n"
     ]
    }
   ],
   "source": [
    "!uv run deepeval set-ollama deepseek-r1:8b\n",
    "!uv run deepeval set-local-embeddings --model-name=mxbai-embed-large --base-url=\"http://localhost:11434/v1/\"  --api-key=\"ollama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9a37552-7598-4ee4-97bf-49948fadeb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "✨ 🚀 ✨ Loading Documents: 100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.55it/s]\n",
      "✨ 📚 ✨ Chunking Documents: 100%|█████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.51it/s]\n",
      "✨ 🧩 ✨ Generating Contexts:   0%|                                                                                | 0/9 [00:00<?, ?it/s]\n",
      "  ✨ 🫗 ✨ Filling Contexts:   0%|                                                                                 | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "  ✨ 🫗 ✨ Filling Contexts:  17%|████████████▏                                                            | 1/6 [00:12<01:04, 12.85s/it]\u001b[A\n",
      "  ✨ 🫗 ✨ Filling Contexts:  50%|████████████████████████████████████▌                                    | 3/6 [00:12<00:10,  3.38s/it]\u001b[A\n",
      "✨ 🧩 ✨ Generating Contexts: 100%|████████████████████████████████████████████████████████████████████████| 9/9 [00:13<00:00,  1.45s/it]  \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough available chunks in smallest document to evaluate chunk quality using the filter threshold: 0.5.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Utilizing <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> out of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> chunks.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Utilizing \u001b[1;36m4\u001b[0m out of \u001b[1;36m4\u001b[0m chunks.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "✨ Generating up to 6 goldens using DeepEval (using deepseek-r1:8b (Ollama) and local embeddings, method=docs):   0%| | 0/6 [00:14<?, ?it\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepeval\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msynthesizer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ContextConstructionConfig\n\u001b[32m      5\u001b[39m synthesizer = Synthesizer()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m goldens = \u001b[43msynthesizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_goldens_from_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocument_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexample.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# , \"example.docx\", \"example.pdf\"]\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext_construction_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mContextConstructionConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m dataset = EvaluationDataset(goldens=goldens)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/go/python-llm-eval/.venv/lib/python3.12/site-packages/deepeval/synthesizer/synthesizer.py:131\u001b[39m, in \u001b[36mSynthesizer.generate_goldens_from_docs\u001b[39m\u001b[34m(self, document_paths, include_expected_output, max_goldens_per_context, context_construction_config, _send_data)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.async_mode:\n\u001b[32m    130\u001b[39m     loop = get_or_create_event_loop()\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     goldens = \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43ma_generate_goldens_from_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdocument_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocument_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m            \u001b[49m\u001b[43minclude_expected_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_expected_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_goldens_per_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_goldens_per_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontext_construction_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext_construction_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_reset_cost\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# Generate contexts from provided docs\u001b[39;00m\n\u001b[32m    142\u001b[39m     context_generator = ContextGenerator(\n\u001b[32m    143\u001b[39m         document_paths=document_paths,\n\u001b[32m    144\u001b[39m         embedder=context_construction_config.embedder,\n\u001b[32m   (...)\u001b[39m\u001b[32m    150\u001b[39m         max_retries=context_construction_config.max_retries,\n\u001b[32m    151\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/go/python-llm-eval/.venv/lib/python3.12/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-macos-aarch64-none/lib/python3.12/asyncio/futures.py:202\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-macos-aarch64-none/lib/python3.12/asyncio/tasks.py:316\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    314\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    319\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/go/python-llm-eval/.venv/lib/python3.12/site-packages/deepeval/synthesizer/synthesizer.py:237\u001b[39m, in \u001b[36mSynthesizer.a_generate_goldens_from_docs\u001b[39m\u001b[34m(self, document_paths, include_expected_output, max_goldens_per_context, context_construction_config, _reset_cost)\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;66;03m# Generate goldens from generated contexts\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m synthesizer_progress_context(\n\u001b[32m    230\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mdocs\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    231\u001b[39m     num_evolutions=\u001b[38;5;28mself\u001b[39m.evolution_config.num_evolutions,\n\u001b[32m   (...)\u001b[39m\u001b[32m    235\u001b[39m     max_generations=\u001b[38;5;28mlen\u001b[39m(contexts) * max_goldens_per_context,\n\u001b[32m    236\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     goldens = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.a_generate_goldens_from_contexts(\n\u001b[32m    238\u001b[39m         contexts=contexts,\n\u001b[32m    239\u001b[39m         include_expected_output=include_expected_output,\n\u001b[32m    240\u001b[39m         max_goldens_per_context=max_goldens_per_context,\n\u001b[32m    241\u001b[39m         source_files=source_files,\n\u001b[32m    242\u001b[39m         _context_scores=context_scores,\n\u001b[32m    243\u001b[39m         _progress_bar=progress_bar,\n\u001b[32m    244\u001b[39m         _reset_cost=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m    246\u001b[39m \u001b[38;5;28mself\u001b[39m.synthetic_goldens.extend(goldens)\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _reset_cost \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cost_tracking \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.using_native_model:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/go/python-llm-eval/.venv/lib/python3.12/site-packages/deepeval/synthesizer/synthesizer.py:420\u001b[39m, in \u001b[36mSynthesizer.a_generate_goldens_from_contexts\u001b[39m\u001b[34m(self, contexts, include_expected_output, max_goldens_per_context, source_files, _context_scores, _progress_bar, _reset_cost)\u001b[39m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m synthesizer_progress_context(\n\u001b[32m    396\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    397\u001b[39m     num_evolutions=\u001b[38;5;28mself\u001b[39m.evolution_config.num_evolutions,\n\u001b[32m   (...)\u001b[39m\u001b[32m    403\u001b[39m     async_mode=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    404\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[32m    405\u001b[39m     tasks = [\n\u001b[32m    406\u001b[39m         \u001b[38;5;28mself\u001b[39m.task_wrapper(\n\u001b[32m    407\u001b[39m             semaphore,\n\u001b[32m   (...)\u001b[39m\u001b[32m    418\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m index, context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(contexts)\n\u001b[32m    419\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*tasks)\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _reset_cost \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cost_tracking \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.using_native_model:\n\u001b[32m    423\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m💰 API cost: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.synthesis_cost\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-macos-aarch64-none/lib/python3.12/asyncio/tasks.py:385\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    388\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-macos-aarch64-none/lib/python3.12/asyncio/tasks.py:314\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/go/python-llm-eval/.venv/lib/python3.12/site-packages/deepeval/synthesizer/synthesizer.py:1005\u001b[39m, in \u001b[36mSynthesizer.task_wrapper\u001b[39m\u001b[34m(self, sem, func, *args, **kwargs)\u001b[39m\n\u001b[32m   1003\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtask_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, sem, func, *args, **kwargs):\n\u001b[32m   1004\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m sem:  \u001b[38;5;66;03m# Acquire semaphore\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1005\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/go/python-llm-eval/.venv/lib/python3.12/site-packages/deepeval/synthesizer/synthesizer.py:445\u001b[39m, in \u001b[36mSynthesizer._a_generate_from_context\u001b[39m\u001b[34m(self, context, goldens, include_expected_output, max_goldens_per_context, source_files, index, progress_bar, context_scores)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_a_generate_from_context\u001b[39m(\n\u001b[32m    427\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    428\u001b[39m     context: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    436\u001b[39m ):\n\u001b[32m    437\u001b[39m     \u001b[38;5;66;03m# Generate inputs\u001b[39;00m\n\u001b[32m    438\u001b[39m     prompt = SynthesizerTemplate.generate_synthetic_inputs(\n\u001b[32m    439\u001b[39m         context=context,\n\u001b[32m    440\u001b[39m         max_goldens_per_context=max_goldens_per_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    443\u001b[39m         input_format=\u001b[38;5;28mself\u001b[39m.styling_config.input_format,\n\u001b[32m    444\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m     synthetic_inputs: List[SyntheticData] = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._a_generate_inputs(\n\u001b[32m    446\u001b[39m         prompt\n\u001b[32m    447\u001b[39m     )\n\u001b[32m    449\u001b[39m     \u001b[38;5;66;03m# Qualify inputs\u001b[39;00m\n\u001b[32m    450\u001b[39m     qualified_synthetic_inputs: List[SyntheticData]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/go/python-llm-eval/.venv/lib/python3.12/site-packages/deepeval/synthesizer/synthesizer.py:722\u001b[39m, in \u001b[36mSynthesizer._a_generate_inputs\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_a_generate_inputs\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m) -> List[SyntheticData]:\n\u001b[32m    719\u001b[39m     res: SyntheticDataList = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._a_generate_schema(\n\u001b[32m    720\u001b[39m         prompt, SyntheticDataList, \u001b[38;5;28mself\u001b[39m.model\n\u001b[32m    721\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m722\u001b[39m     synthetic_data_items = \u001b[43mres\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\n\u001b[32m    723\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m synthetic_data_items\n",
      "\u001b[31mAttributeError\u001b[39m: 'tuple' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "from deepeval.dataset import EvaluationDataset\n",
    "from deepeval.synthesizer import Synthesizer\n",
    "from deepeval.synthesizer.config import ContextConstructionConfig\n",
    "\n",
    "synthesizer = Synthesizer()\n",
    "goldens = synthesizer.generate_goldens_from_docs(\n",
    "    document_paths=[\"example.txt\"],  # , \"example.docx\", \"example.pdf\"]\n",
    "    context_construction_config=ContextConstructionConfig(chunk_size=200),\n",
    ")\n",
    "\n",
    "dataset = EvaluationDataset(goldens=goldens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b64a63-66fc-47e9-ac27-7186f98f28a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesizer.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
